{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: rtdl in /home/lily_l/miniconda/envs/phish/lib/python3.11/site-packages (0.0.13)\n",
      "Requirement already satisfied: numpy<2,>=1.18 in /home/lily_l/miniconda/envs/phish/lib/python3.11/site-packages (from rtdl) (1.24.1)\n",
      "Requirement already satisfied: torch<2,>=1.7 in /home/lily_l/miniconda/envs/phish/lib/python3.11/site-packages (from rtdl) (1.13.0.post200)\n",
      "Requirement already satisfied: typing_extensions in /home/lily_l/miniconda/envs/phish/lib/python3.11/site-packages (from torch<2,>=1.7->rtdl) (4.1.1)\n",
      "Requirement already satisfied: libzero==0.0.4 in /home/lily_l/miniconda/envs/phish/lib/python3.11/site-packages (0.0.4)\n",
      "Requirement already satisfied: numpy<2,>=1.17 in /home/lily_l/miniconda/envs/phish/lib/python3.11/site-packages (from libzero==0.0.4) (1.24.1)\n",
      "Requirement already satisfied: pynvml<9,>=8.0 in /home/lily_l/miniconda/envs/phish/lib/python3.11/site-packages (from libzero==0.0.4) (8.0.4)\n",
      "Requirement already satisfied: torch<2,>=1.6 in /home/lily_l/miniconda/envs/phish/lib/python3.11/site-packages (from libzero==0.0.4) (1.13.0.post200)\n",
      "Requirement already satisfied: tqdm<5,>=4.0 in /home/lily_l/miniconda/envs/phish/lib/python3.11/site-packages (from libzero==0.0.4) (4.63.0)\n",
      "Requirement already satisfied: typing_extensions in /home/lily_l/miniconda/envs/phish/lib/python3.11/site-packages (from torch<2,>=1.6->libzero==0.0.4) (4.1.1)\n"
     ]
    }
   ],
   "source": [
    "# Requirements:\n",
    "!pip install rtdl\n",
    "!pip install libzero==0.0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Dict\n",
    "\n",
    "import numpy as np\n",
    "import rtdl\n",
    "import scipy.special\n",
    "import sklearn.datasets\n",
    "import sklearn.metrics\n",
    "import sklearn.model_selection\n",
    "import sklearn.preprocessing\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import zero\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "123456"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda:5')\n",
    "# Docs: https://yura52.github.io/delu/0.0.4/reference/api/zero.improve_reproducibility.html\n",
    "zero.improve_reproducibility(seed=123456)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "10c8b011",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/dataset_full.csv\")\n",
    "\n",
    "x = df.drop(labels='phishing', axis=1)\n",
    "y = df['phishing']\n",
    "\n",
    "dataset = sklearn.datasets.fetch_california_housing()\n",
    "task_type = 'binclass'\n",
    "\n",
    "# dataset = sklearn.datasets.fetch_covtype()\n",
    "# task_type = 'multiclass'\n",
    "\n",
    "assert task_type in ['binclass', 'multiclass', 'regression']\n",
    "\n",
    "X_all = x.astype('float32')\n",
    "y_all = y.astype('float32' if task_type == 'regression' else 'int64')\n",
    "if task_type != 'regression':\n",
    "    y_all = sklearn.preprocessing.LabelEncoder().fit_transform(y_all).astype('int64')\n",
    "n_classes = int(max(y_all)) + 1 if task_type == 'multiclass' else None\n",
    "\n",
    "X = {}\n",
    "y = {}\n",
    "X['train'], X['test'], y['train'], y['test'] = sklearn.model_selection.train_test_split(\n",
    "    X_all, y_all, train_size=0.8\n",
    ")\n",
    "X['train'], X['val'], y['train'], y['val'] = sklearn.model_selection.train_test_split(\n",
    "    X['train'], y['train'], train_size=0.8\n",
    ")\n",
    "\n",
    "# not the best way to preprocess features, but enough for the demonstration\n",
    "preprocess = sklearn.preprocessing.StandardScaler().fit(X['train'])\n",
    "X = {\n",
    "    k: torch.tensor(preprocess.transform(v), device=device)\n",
    "    for k, v in X.items()\n",
    "}\n",
    "y = {k: torch.tensor(v, device=device) for k, v in y.items()}\n",
    "\n",
    "# !!! CRUCIAL for neural networks when solving regression problems !!!\n",
    "if task_type == 'regression':\n",
    "    y_mean = y['train'].mean().item()\n",
    "    y_std = y['train'].std().item()\n",
    "    y = {k: (v - y_mean) / y_std for k, v in y.items()}\n",
    "else:\n",
    "    y_std = y_mean = None\n",
    "\n",
    "if task_type != 'multiclass':\n",
    "    y = {k: v.float() for k, v in y.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model\n",
    "Carefully read the comments and uncomment the code for the model you want to test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_out = n_classes or 1\n",
    "\n",
    "model = rtdl.MLP.make_baseline(\n",
    "    d_in=X_all.shape[1],\n",
    "    d_layers=[128, 256, 128],\n",
    "    dropout=0.1,\n",
    "    d_out=d_out,\n",
    ")\n",
    "lr = 0.001\n",
    "weight_decay = 0.0\n",
    "\n",
    "# model = rtdl.ResNet.make_baseline(\n",
    "#     d_in=X_all.shape[1],\n",
    "#     d_main=128,\n",
    "#     d_intermediate=256,\n",
    "#     dropout_first=0.2,\n",
    "#     dropout_second=0.0,\n",
    "#     n_blocks=2,\n",
    "#     d_out=d_out,\n",
    "# )\n",
    "# lr = 0.001\n",
    "# weight_decay = 0.0\n",
    "\n",
    "# model = rtdl.FTTransformer.make_default(\n",
    "#     n_num_features=X_all.shape[1],\n",
    "#     cat_cardinalities=None,\n",
    "#     last_layer_query_idx=[-1],  # it makes the model faster and does NOT affect its output\n",
    "#     d_out=d_out,\n",
    "# )\n",
    "\n",
    "# === ABOUT CATEGORICAL FEATURES ===\n",
    "# IF you use MLP, ResNet or any other simple feed-forward model (NOT transformer-based model)\n",
    "# AND there are categorical features\n",
    "# THEN you have to implement a wrapper that handles categorical features.\n",
    "# The example below demonstrates how it can be achieved using rtdl.CategoricalFeatureTokenizer.\n",
    "# ==================================\n",
    "# 1. When you have both numerical and categorical features, you should prepare you data like this:\n",
    "#    (X_num<float32>, X_cat<int64>) instead of X<float32>\n",
    "#    Each column in X_cat should contain values within the range from 0 to <(the number of unique values in column) - 1>;\n",
    "#    use sklean.preprocessing.OrdinalEncoder to achieve this;\n",
    "# 2. Prepare a list of so called \"cardinalities\":\n",
    "#    cardinalities[i] = <the number of unique values of the i-th categorical feature>\n",
    "# 3. See the commented example below and adapt it for your needs.\n",
    "#\n",
    "# class Model(nn.Module):\n",
    "#     def __init__(\n",
    "#         self,\n",
    "#         n_num_features: int,\n",
    "#         cat_tokenizer: rtdl.CategoricalFeatureTokenizer,\n",
    "#         mlp_kwargs: Dict[str, Any],\n",
    "#     ):\n",
    "#         super().__init__()\n",
    "#         self.cat_tokenizer = cat_tokenizer\n",
    "#         self.model = rtdl.MLP.make_baseline(\n",
    "#             d_in=n_num_features + cat_tokenizer.n_tokens * cat_tokenizer.d_token,\n",
    "#             **mlp_kwargs,\n",
    "#         )\n",
    "#\n",
    "#     def forward(self, x_num, x_cat):\n",
    "#         return self.model(\n",
    "#             torch.cat([x_num, self.cat_tokenizer(x_cat).flatten(1, -1)], dim=1)\n",
    "#         )\n",
    "#\n",
    "# model = Model(\n",
    "#     # `None` means \"Do not transform numerical features\"\n",
    "#     # `d_token` is the size of embedding for ONE categorical feature\n",
    "#     X_num_all.shape[1],\n",
    "#     rtdl.CategoricalFeatureTokenizer(cardinalities, d_token, True, 'uniform'),\n",
    "#     mlp_kwargs,\n",
    "# )\n",
    "# Then the model should be used as `model(x_num, x_cat)` instead of of `model(x)`.\n",
    "\n",
    "model.to(device)\n",
    "optimizer = (\n",
    "    model.make_default_optimizer()\n",
    "    if isinstance(model, rtdl.FTTransformer)\n",
    "    else torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    ")\n",
    "loss_fn = (\n",
    "    F.binary_cross_entropy_with_logits\n",
    "    if task_type == 'binclass'\n",
    "    else F.cross_entropy\n",
    "    if task_type == 'multiclass'\n",
    "    else F.mse_loss\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score before training: 0.4343\n"
     ]
    }
   ],
   "source": [
    "def apply_model(x_num, x_cat=None):\n",
    "    if isinstance(model, rtdl.FTTransformer):\n",
    "        return model(x_num, x_cat)\n",
    "    elif isinstance(model, (rtdl.MLP, rtdl.ResNet)):\n",
    "        assert x_cat is None\n",
    "        return model(x_num)\n",
    "    else:\n",
    "        raise NotImplementedError(\n",
    "            f'Looks like you are using a custom model: {type(model)}.'\n",
    "            ' Then you have to implement this branch first.'\n",
    "        )\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(part):\n",
    "    model.eval()\n",
    "    prediction = []\n",
    "    for batch in zero.iter_batches(X[part], 1024):\n",
    "        prediction.append(apply_model(batch))\n",
    "    prediction = torch.cat(prediction).squeeze(1).cpu().numpy()\n",
    "    target = y[part].cpu().numpy()\n",
    "\n",
    "    if task_type == 'binclass':\n",
    "        prediction = np.round(scipy.special.expit(prediction))\n",
    "        score = sklearn.metrics.accuracy_score(target, prediction)\n",
    "    elif task_type == 'multiclass':\n",
    "        prediction = prediction.argmax(1)\n",
    "        score = sklearn.metrics.accuracy_score(target, prediction)\n",
    "    else:\n",
    "        assert task_type == 'regression'\n",
    "        score = sklearn.metrics.mean_squared_error(target, prediction) ** 0.5 * y_std\n",
    "    return score\n",
    "\n",
    "\n",
    "# Create a dataloader for batches of indices\n",
    "# Docs: https://yura52.github.io/delu/reference/api/zero.data.IndexLoader.html\n",
    "batch_size = 256\n",
    "train_loader = zero.data.IndexLoader(len(X['train']), batch_size, device=device)\n",
    "\n",
    "# Create a progress tracker for early stopping\n",
    "# Docs: https://yura52.github.io/delu/reference/api/zero.ProgressTracker.html\n",
    "progress = zero.ProgressTracker(patience=100)\n",
    "\n",
    "print(f'Test score before training: {evaluate(\"test\"):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001 | Validation score: 0.9387 | Test score: 0.9402 <<< BEST VALIDATION EPOCH\n",
      "Epoch 002 | Validation score: 0.9491 | Test score: 0.9503 <<< BEST VALIDATION EPOCH\n",
      "Epoch 003 | Validation score: 0.9512 | Test score: 0.9526 <<< BEST VALIDATION EPOCH\n",
      "Epoch 004 | Validation score: 0.9538 | Test score: 0.9554 <<< BEST VALIDATION EPOCH\n",
      "Epoch 005 | Validation score: 0.9562 | Test score: 0.9567 <<< BEST VALIDATION EPOCH\n",
      "Epoch 006 | Validation score: 0.9574 | Test score: 0.9582 <<< BEST VALIDATION EPOCH\n",
      "Epoch 007 | Validation score: 0.9583 | Test score: 0.9581 <<< BEST VALIDATION EPOCH\n",
      "Epoch 008 | Validation score: 0.9561 | Test score: 0.9571\n",
      "Epoch 009 | Validation score: 0.9592 | Test score: 0.9588 <<< BEST VALIDATION EPOCH\n",
      "Epoch 010 | Validation score: 0.9595 | Test score: 0.9585 <<< BEST VALIDATION EPOCH\n",
      "Epoch 011 | Validation score: 0.9582 | Test score: 0.9589\n",
      "Epoch 012 | Validation score: 0.9592 | Test score: 0.9592\n",
      "Epoch 013 | Validation score: 0.9595 | Test score: 0.9596\n",
      "Epoch 014 | Validation score: 0.9595 | Test score: 0.9597\n",
      "Epoch 015 | Validation score: 0.9607 | Test score: 0.9609 <<< BEST VALIDATION EPOCH\n",
      "Epoch 016 | Validation score: 0.9614 | Test score: 0.9597 <<< BEST VALIDATION EPOCH\n",
      "Epoch 017 | Validation score: 0.9588 | Test score: 0.9590\n",
      "Epoch 018 | Validation score: 0.9619 | Test score: 0.9613 <<< BEST VALIDATION EPOCH\n",
      "Epoch 019 | Validation score: 0.9607 | Test score: 0.9611\n",
      "Epoch 020 | Validation score: 0.9608 | Test score: 0.9596\n",
      "Epoch 021 | Validation score: 0.9607 | Test score: 0.9614\n",
      "Epoch 022 | Validation score: 0.9607 | Test score: 0.9612\n",
      "Epoch 023 | Validation score: 0.9614 | Test score: 0.9626\n",
      "Epoch 024 | Validation score: 0.9612 | Test score: 0.9610\n",
      "Epoch 025 | Validation score: 0.9602 | Test score: 0.9614\n",
      "Epoch 026 | Validation score: 0.9602 | Test score: 0.9625\n",
      "Epoch 027 | Validation score: 0.9602 | Test score: 0.9614\n",
      "Epoch 028 | Validation score: 0.9607 | Test score: 0.9617\n",
      "Epoch 029 | Validation score: 0.9596 | Test score: 0.9611\n",
      "Epoch 030 | Validation score: 0.9621 | Test score: 0.9624 <<< BEST VALIDATION EPOCH\n",
      "Epoch 031 | Validation score: 0.9612 | Test score: 0.9616\n",
      "Epoch 032 | Validation score: 0.9612 | Test score: 0.9610\n",
      "Epoch 033 | Validation score: 0.9600 | Test score: 0.9616\n",
      "Epoch 034 | Validation score: 0.9615 | Test score: 0.9633\n",
      "Epoch 035 | Validation score: 0.9624 | Test score: 0.9622 <<< BEST VALIDATION EPOCH\n",
      "Epoch 036 | Validation score: 0.9625 | Test score: 0.9626 <<< BEST VALIDATION EPOCH\n",
      "Epoch 037 | Validation score: 0.9612 | Test score: 0.9632\n",
      "Epoch 038 | Validation score: 0.9605 | Test score: 0.9610\n",
      "Epoch 039 | Validation score: 0.9591 | Test score: 0.9613\n",
      "Epoch 040 | Validation score: 0.9603 | Test score: 0.9619\n",
      "Epoch 041 | Validation score: 0.9633 | Test score: 0.9634 <<< BEST VALIDATION EPOCH\n",
      "Epoch 042 | Validation score: 0.9610 | Test score: 0.9614\n",
      "Epoch 043 | Validation score: 0.9614 | Test score: 0.9619\n",
      "Epoch 044 | Validation score: 0.9619 | Test score: 0.9637\n",
      "Epoch 045 | Validation score: 0.9616 | Test score: 0.9610\n",
      "Epoch 046 | Validation score: 0.9613 | Test score: 0.9627\n",
      "Epoch 047 | Validation score: 0.9608 | Test score: 0.9625\n",
      "Epoch 048 | Validation score: 0.9636 | Test score: 0.9633 <<< BEST VALIDATION EPOCH\n",
      "Epoch 049 | Validation score: 0.9603 | Test score: 0.9619\n",
      "Epoch 050 | Validation score: 0.9605 | Test score: 0.9618\n",
      "Epoch 051 | Validation score: 0.9617 | Test score: 0.9618\n",
      "Epoch 052 | Validation score: 0.9602 | Test score: 0.9627\n",
      "Epoch 053 | Validation score: 0.9597 | Test score: 0.9604\n",
      "Epoch 054 | Validation score: 0.9616 | Test score: 0.9602\n",
      "Epoch 055 | Validation score: 0.9595 | Test score: 0.9610\n",
      "Epoch 056 | Validation score: 0.9615 | Test score: 0.9618\n",
      "Epoch 057 | Validation score: 0.9627 | Test score: 0.9631\n",
      "Epoch 058 | Validation score: 0.9612 | Test score: 0.9619\n",
      "Epoch 059 | Validation score: 0.9622 | Test score: 0.9630\n",
      "Epoch 060 | Validation score: 0.9632 | Test score: 0.9625\n",
      "Epoch 061 | Validation score: 0.9637 | Test score: 0.9646 <<< BEST VALIDATION EPOCH\n",
      "Epoch 062 | Validation score: 0.9619 | Test score: 0.9628\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m     loss \u001b[39m=\u001b[39m loss_fn(apply_model(x_batch)\u001b[39m.\u001b[39msqueeze(\u001b[39m1\u001b[39m), y_batch)\n\u001b[1;32m     10\u001b[0m     loss\u001b[39m.\u001b[39mbackward()\n\u001b[0;32m---> 11\u001b[0m     optimizer\u001b[39m.\u001b[39mstep()\n\u001b[1;32m     12\u001b[0m     \u001b[39m# if iteration % report_frequency == 0:\u001b[39;00m\n\u001b[1;32m     13\u001b[0m     \u001b[39m#     print(f'(epoch) {epoch} (batch) {iteration} (loss) {loss.item():.4f}')\u001b[39;00m\n\u001b[1;32m     15\u001b[0m val_score \u001b[39m=\u001b[39m evaluate(\u001b[39m'\u001b[39m\u001b[39mval\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda/envs/phish/lib/python3.11/site-packages/torch/optim/optimizer.py:140\u001b[0m, in \u001b[0;36mOptimizer._hook_for_profile.<locals>.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m profile_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mOptimizer.step#\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.step\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(obj\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m)\n\u001b[1;32m    139\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mautograd\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mrecord_function(profile_name):\n\u001b[0;32m--> 140\u001b[0m     out \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    141\u001b[0m     obj\u001b[39m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    142\u001b[0m     \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/miniconda/envs/phish/lib/python3.11/site-packages/torch/autograd/grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m     25\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     26\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclone():\n\u001b[0;32m---> 27\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda/envs/phish/lib/python3.11/site-packages/torch/optim/adamw.py:162\u001b[0m, in \u001b[0;36mAdamW.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    158\u001b[0m             max_exp_avg_sqs\u001b[39m.\u001b[39mappend(state[\u001b[39m'\u001b[39m\u001b[39mmax_exp_avg_sq\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m    160\u001b[0m         state_steps\u001b[39m.\u001b[39mappend(state[\u001b[39m'\u001b[39m\u001b[39mstep\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m--> 162\u001b[0m     adamw(params_with_grad,\n\u001b[1;32m    163\u001b[0m           grads,\n\u001b[1;32m    164\u001b[0m           exp_avgs,\n\u001b[1;32m    165\u001b[0m           exp_avg_sqs,\n\u001b[1;32m    166\u001b[0m           max_exp_avg_sqs,\n\u001b[1;32m    167\u001b[0m           state_steps,\n\u001b[1;32m    168\u001b[0m           amsgrad\u001b[39m=\u001b[39mamsgrad,\n\u001b[1;32m    169\u001b[0m           beta1\u001b[39m=\u001b[39mbeta1,\n\u001b[1;32m    170\u001b[0m           beta2\u001b[39m=\u001b[39mbeta2,\n\u001b[1;32m    171\u001b[0m           lr\u001b[39m=\u001b[39mgroup[\u001b[39m'\u001b[39m\u001b[39mlr\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[1;32m    172\u001b[0m           weight_decay\u001b[39m=\u001b[39mgroup[\u001b[39m'\u001b[39m\u001b[39mweight_decay\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[1;32m    173\u001b[0m           eps\u001b[39m=\u001b[39mgroup[\u001b[39m'\u001b[39m\u001b[39meps\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[1;32m    174\u001b[0m           maximize\u001b[39m=\u001b[39mgroup[\u001b[39m'\u001b[39m\u001b[39mmaximize\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[1;32m    175\u001b[0m           foreach\u001b[39m=\u001b[39mgroup[\u001b[39m'\u001b[39m\u001b[39mforeach\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[1;32m    176\u001b[0m           capturable\u001b[39m=\u001b[39mgroup[\u001b[39m'\u001b[39m\u001b[39mcapturable\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m    178\u001b[0m \u001b[39mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/miniconda/envs/phish/lib/python3.11/site-packages/torch/optim/adamw.py:219\u001b[0m, in \u001b[0;36madamw\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    217\u001b[0m     func \u001b[39m=\u001b[39m _single_tensor_adamw\n\u001b[0;32m--> 219\u001b[0m func(params,\n\u001b[1;32m    220\u001b[0m      grads,\n\u001b[1;32m    221\u001b[0m      exp_avgs,\n\u001b[1;32m    222\u001b[0m      exp_avg_sqs,\n\u001b[1;32m    223\u001b[0m      max_exp_avg_sqs,\n\u001b[1;32m    224\u001b[0m      state_steps,\n\u001b[1;32m    225\u001b[0m      amsgrad\u001b[39m=\u001b[39mamsgrad,\n\u001b[1;32m    226\u001b[0m      beta1\u001b[39m=\u001b[39mbeta1,\n\u001b[1;32m    227\u001b[0m      beta2\u001b[39m=\u001b[39mbeta2,\n\u001b[1;32m    228\u001b[0m      lr\u001b[39m=\u001b[39mlr,\n\u001b[1;32m    229\u001b[0m      weight_decay\u001b[39m=\u001b[39mweight_decay,\n\u001b[1;32m    230\u001b[0m      eps\u001b[39m=\u001b[39meps,\n\u001b[1;32m    231\u001b[0m      maximize\u001b[39m=\u001b[39mmaximize,\n\u001b[1;32m    232\u001b[0m      capturable\u001b[39m=\u001b[39mcapturable)\n",
      "File \u001b[0;32m~/miniconda/envs/phish/lib/python3.11/site-packages/torch/optim/adamw.py:316\u001b[0m, in \u001b[0;36m_single_tensor_adamw\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable)\u001b[0m\n\u001b[1;32m    314\u001b[0m     denom \u001b[39m=\u001b[39m (max_exp_avg_sqs[i]\u001b[39m.\u001b[39msqrt() \u001b[39m/\u001b[39m bias_correction2_sqrt)\u001b[39m.\u001b[39madd_(eps)\n\u001b[1;32m    315\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 316\u001b[0m     denom \u001b[39m=\u001b[39m (exp_avg_sq\u001b[39m.\u001b[39msqrt() \u001b[39m/\u001b[39m bias_correction2_sqrt)\u001b[39m.\u001b[39madd_(eps)\n\u001b[1;32m    318\u001b[0m param\u001b[39m.\u001b[39maddcdiv_(exp_avg, denom, value\u001b[39m=\u001b[39m\u001b[39m-\u001b[39mstep_size)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_epochs = 100\n",
    "report_frequency = len(X['train']) // batch_size // 5\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    for iteration, batch_idx in enumerate(train_loader):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        x_batch = X['train'][batch_idx]\n",
    "        y_batch = y['train'][batch_idx]\n",
    "        loss = loss_fn(apply_model(x_batch).squeeze(1), y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # if iteration % report_frequency == 0:\n",
    "        #     print(f'(epoch) {epoch} (batch) {iteration} (loss) {loss.item():.4f}')\n",
    "\n",
    "    val_score = evaluate('val')\n",
    "    test_score = evaluate('test')\n",
    "    print(f'Epoch {epoch:03d} | Validation score: {val_score:.4f} | Test score: {test_score:.4f}', end='')\n",
    "    progress.update((-1 if task_type == 'regression' else 1) * val_score)\n",
    "    if progress.success:\n",
    "        # print(f'Epoch {epoch:03d} | Validation score: {val_score:.4f} | Test score: {test_score:.4f}', end='')\n",
    "        print(' <<< BEST VALIDATION EPOCH', end='')\n",
    "    print()\n",
    "    if progress.fail:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
